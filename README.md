# nlp-study

## Attention Is All You Need (ë‚˜ë™ë¹ˆ)

ğŸ’» code from [github](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Attention_is_All_You_Need_Tutorial_(German_English).ipynb) - ë‚˜ë™ë¹ˆ

ğŸ“„ [Original Paper Link](https://arxiv.org/abs/1706.03762)

ğŸ“¹ [Paper Review Video](https://www.youtube.com/watch?v=AA621UofTUA&ab_channel=%EB%8F%99%EB%B9%88%EB%82%98) - ë‚˜ë™ë¹ˆ

ğŸ“ [Summary PDF](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/lecture_notes/Transformer.pdf) - ë‚˜ë™ë¹ˆ

<br>

## BERT (E-book)

ğŸ’» code from [wikidocs](https://wikidocs.net/109251) - ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸

ğŸ’» code from [github](https://github.com/LaJeremi/Tensorflow-nlp-tutorial-Practice-/blob/0c862ebe1966546b0b5b95aed26a36af0bb560d6/18.%20Fine-tuning%20BERT%20(Cls%2C%20NER%2C%20NLI)/%2018_03_google_bert_nsmc_tpu.ipynb) - LaJeremi

<br>

## BERT (SKplanet Tacademy)

ğŸ’» code from [google drive](https://drive.google.com/drive/folders/1QQphR2tmk5g6BheZKZ5q8WhX5yixV8xZ) - SKplanet Tacademy

ğŸ“¹ Explanation Video [<1. BERT>](https://www.youtube.com/watch?v=riGc8z3YIgQ&t=2s&ab_channel=SKplanetTacademy) 
[<2. KorBERT>](https://www.youtube.com/watch?v=PzvKDpQgNzc&ab_channel=SKplanetTacademy) 
[<3. BERT Training>](https://www.youtube.com/watch?v=S42vDzJExIA&t=368s&ab_channel=SKplanetTacademy) - SKplanet Tacademy

> Tensorflow ver1ìœ¼ë¡œ ì‘ì„±ë˜ì–´, ver2ë¡œ ì—…ê·¸ë ˆì´ë“œ í•˜ëŠ”ë° ì‹¤íŒ¨í•¨ (contrib)

```python
import tensorflow.compat.v1 as tf

tf.contrib # error
```

> Unable to render rich display (github colab displayê°€ ì•ˆë¨)
> 
<br>

## BERT (graycode)

ğŸ’» code from [github](https://github.com/graykode/nlp-tutorial) - graycode

<br>

## BERT (ê¹€ì›…ê³¤)

ğŸ’» code from [github](https://github.com/kimwoonggon/publicservant_AI) - ê¹€ì›…ê³¤

ğŸ“¹ Explanation Video [<1. naver_sentiment>](https://www.youtube.com/watch?v=OOfCI8R0jr8&ab_channel=%EA%B9%80%EC%9B%85%EA%B3%A4) 
[<2. Q&A>](https://www.youtube.com/watch?v=LuApA264Wbs&ab_channel=%EA%B9%80%EC%9B%85%EA%B3%A4) - ê¹€ì›…ê³¤

<br>

## BERT (google research)

ğŸ’» code from [github](https://github.com/google-research/bert) (BERT-Base, Multilingual Cased) - google research

ğŸ“„ [Original Paper Link](https://arxiv.org/abs/1810.04805)

<br>

## BPE: Byte Pair Encoding

ğŸ’» code from [github](https://github.com/BurningFalls/nlp-study/blob/main/Byte%20Pair%20Encoding/BPE.ipynb) - ì´ì„±ì£¼

ğŸ“„ [Original Paper Link](https://arxiv.org/abs/1508.07909)

<br>

## Transformer

ğŸ’» code from [github](https://github.com/graykode/nlp-tutorial) - graycode

ğŸ“ library lecture from [wikidocs](https://wikidocs.net/book/8056)
